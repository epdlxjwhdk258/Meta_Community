{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb49d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix\n",
    "import community as community_louvain\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "df1 = pd.read_parquet('/Users/kookbab/Desktop/연구 정리 KCI/코드/04.making_graphs/numerical_values/COS_bert_word_embed.parquet', engine='pyarrow').set_index('word')\n",
    "df1.columns = df1.index\n",
    "\n",
    "df2 = pd.read_parquet('/Users/kookbab/Desktop/연구 정리 KCI/코드/04.making_graphs/numerical_values/COS_bert_word_topic_sim.parquet', engine='pyarrow').set_index('word')\n",
    "df2.columns = df2.index\n",
    "\n",
    "df3 = pd.read_parquet('/Users/kookbab/Desktop/연구 정리 KCI/코드/04.making_graphs/numerical_values/COS_lda_word_topic_prob.parquet', engine='pyarrow').set_index('word')\n",
    "df3.columns = df3.index\n",
    "\n",
    "\n",
    "# 단어 순서 섞어주기\n",
    "words_shuffled = df1.index.tolist()\n",
    "random.shuffle(words_shuffled)\n",
    "df1 = df1.loc[words_shuffled, words_shuffled]\n",
    "df2 = df2.loc[words_shuffled, words_shuffled]\n",
    "df3 = df3.loc[words_shuffled, words_shuffled]\n",
    "\n",
    "# 0 제거\n",
    "df1[df1 < 0] = 0\n",
    "df2[df2 < 0] = 0\n",
    "df3[df3 < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22727d2",
   "metadata": {},
   "source": [
    "# Make Graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf0a91",
   "metadata": {},
   "source": [
    "## individual graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f24fd",
   "metadata": {},
   "source": [
    "# threshold 없음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc09a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sim1: 100%|██████████| 2597/2597 [00:28<00:00, 92.05it/s] \n",
      "Creating sim2: 100%|██████████| 2597/2597 [00:26<00:00, 98.98it/s] \n",
      "Creating sim3: 100%|██████████| 2597/2597 [00:26<00:00, 97.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 (sim1) - 노드 수: 2597, 엣지 수: 3370906\n",
      "G2 (sim2) - 노드 수: 2597, 엣지 수: 3370906\n",
      "G3 (sim3) - 노드 수: 2597, 엣지 수: 3370906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 함수: 유사도 행렬 → 단일 그래프 생성\n",
    "def create_graph_from_df(df, label):\n",
    "    G = nx.Graph()\n",
    "    words = df.index.tolist()\n",
    "    G.add_nodes_from(words)\n",
    "    \n",
    "    for i, word_i in tqdm(enumerate(df.index), total=len(df), desc=f\"Creating {label}\"):\n",
    "        for j in range(i + 1, len(df.columns)):\n",
    "            word_j = df.columns[j]\n",
    "            weight = df.iat[i, j]\n",
    "            G.add_edge(word_i, word_j, weight=weight, type=label)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# 개별 그래프 생성\n",
    "G1 = create_graph_from_df(df1, 'sim1')\n",
    "G2 = create_graph_from_df(df2, 'sim2')\n",
    "G3 = create_graph_from_df(df3, 'sim3')\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"G1 (sim1) - 노드 수: {G1.number_of_nodes()}, 엣지 수: {G1.number_of_edges()}\")\n",
    "print(f\"G2 (sim2) - 노드 수: {G2.number_of_nodes()}, 엣지 수: {G2.number_of_edges()}\")\n",
    "print(f\"G3 (sim3) - 노드 수: {G3.number_of_nodes()}, 엣지 수: {G3.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8047aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엣지 개수: 3370906\n",
      "최소 weight: 0.0\n",
      "최대 weight: 0.9958657439066876\n",
      "평균 weight: 0.60\n",
      "중앙값 weight: 0.6054310913910537\n",
      "표준편차: 0.17\n"
     ]
    }
   ],
   "source": [
    "# 모든 weight 값 추출\n",
    "weights = [data['weight'] for _, _, data in G1.edges(data=True)]\n",
    "\n",
    "# 통계값 계산\n",
    "print(f\"엣지 개수: {len(weights)}\")\n",
    "print(f\"최소 weight: {np.min(weights)}\")\n",
    "print(f\"최대 weight: {np.max(weights)}\")\n",
    "print(f\"평균 weight: {np.mean(weights):.2f}\")\n",
    "print(f\"중앙값 weight: {np.median(weights)}\")\n",
    "print(f\"표준편차: {np.std(weights):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd48960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엣지 개수: 3370906\n",
      "최소 weight: 0.0883820220823126\n",
      "최대 weight: 0.9999488179664748\n",
      "평균 weight: 0.98\n",
      "중앙값 weight: 0.9847848778110468\n",
      "표준편차: 0.03\n"
     ]
    }
   ],
   "source": [
    "# 모든 weight 값 추출\n",
    "weights = [data['weight'] for _, _, data in G2.edges(data=True)]\n",
    "\n",
    "# 통계값 계산\n",
    "print(f\"엣지 개수: {len(weights)}\")\n",
    "print(f\"최소 weight: {np.min(weights)}\")\n",
    "print(f\"최대 weight: {np.max(weights)}\")\n",
    "print(f\"평균 weight: {np.mean(weights):.2f}\")\n",
    "print(f\"중앙값 weight: {np.median(weights)}\")\n",
    "print(f\"표준편차: {np.std(weights):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75bf80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엣지 개수: 3370906\n",
      "최소 weight: 0.0005424193774261279\n",
      "최대 weight: 0.999999508369228\n",
      "평균 weight: 0.19\n",
      "중앙값 weight: 0.1265978945886176\n",
      "표준편차: 0.18\n"
     ]
    }
   ],
   "source": [
    "# 모든 weight 값 추출\n",
    "weights = [data['weight'] for _, _, data in G3.edges(data=True)]\n",
    "\n",
    "# 통계값 계산\n",
    "print(f\"엣지 개수: {len(weights)}\")\n",
    "print(f\"최소 weight: {np.min(weights)}\")\n",
    "print(f\"최대 weight: {np.max(weights)}\")\n",
    "print(f\"평균 weight: {np.mean(weights):.2f}\")\n",
    "print(f\"중앙값 weight: {np.median(weights)}\")\n",
    "print(f\"표준편차: {np.std(weights):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ef0c9",
   "metadata": {},
   "source": [
    "## 각 그래프에 대한 community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42402593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim1 커뮤니티 수: 821\n",
      "sim2 커뮤니티 수: 893\n",
      "sim3 커뮤니티 수: 626\n"
     ]
    }
   ],
   "source": [
    "def get_louvain_partition(G, label, res):\n",
    "    partition = community_louvain.best_partition(G, weight='weight', resolution=res, random_state=RANDOM_STATE)\n",
    "    return pd.DataFrame(list(partition.items()), columns=['word', f'community_{label}'])\n",
    "\n",
    "df_comm1 = get_louvain_partition(G1, 'sim1', 1.2) # 1.2\n",
    "df_comm2 = get_louvain_partition(G2, 'sim2', 1.01) # 1.01\n",
    "df_comm3 = get_louvain_partition(G3, 'sim3', 3.3) # 3.3 \n",
    "\n",
    "print(f\"sim1 커뮤니티 수: {df_comm1['community_sim1'].nunique()}\")\n",
    "print(f\"sim2 커뮤니티 수: {df_comm2['community_sim2'].nunique()}\")\n",
    "print(f\"sim3 커뮤니티 수: {df_comm3['community_sim3'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d18092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 기준 병합\n",
    "df_merged = df_comm1.merge(df_comm2, on='word').merge(df_comm3, on='word')\n",
    "df_merged = df_merged.set_index('word')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b9d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community_sim1</th>\n",
       "      <th>community_sim2</th>\n",
       "      <th>community_sim3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>인수</th>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주민</th>\n",
       "      <td>1</td>\n",
       "      <td>617</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당부</th>\n",
       "      <td>2</td>\n",
       "      <td>378</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시작</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>오픈</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사건</th>\n",
       "      <td>498</td>\n",
       "      <td>617</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>생태</th>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수용</th>\n",
       "      <td>789</td>\n",
       "      <td>576</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>검사</th>\n",
       "      <td>29</td>\n",
       "      <td>281</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>단위</th>\n",
       "      <td>303</td>\n",
       "      <td>282</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      community_sim1  community_sim2  community_sim3\n",
       "word                                                \n",
       "인수                 0             184              58\n",
       "주민                 1             617             290\n",
       "당부                 2             378             509\n",
       "시작                 3               3               3\n",
       "오픈                 4               4               4\n",
       "...              ...             ...             ...\n",
       "사건               498             617             592\n",
       "생태               156             184             518\n",
       "수용               789             576             480\n",
       "검사                29             281             175\n",
       "단위               303             282             474\n",
       "\n",
       "[2597 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b09cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del df_comm1, df_comm2, df_comm3, G1, G2, G3\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0e456",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba1b3e",
   "metadata": {},
   "source": [
    "## OneHotEncoder (Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e8bcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2330</th>\n",
       "      <th>2331</th>\n",
       "      <th>2332</th>\n",
       "      <th>2333</th>\n",
       "      <th>2334</th>\n",
       "      <th>2335</th>\n",
       "      <th>2336</th>\n",
       "      <th>2337</th>\n",
       "      <th>2338</th>\n",
       "      <th>2339</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>인수</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주민</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당부</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시작</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>오픈</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사건</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>생태</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수용</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>검사</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>단위</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2597 rows × 2340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  2330  \\\n",
       "word                                                              ...         \n",
       "인수     1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "주민     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "당부     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "시작     0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "오픈     0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "사건     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "생태     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "수용     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "검사     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "단위     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "      2331  2332  2333  2334  2335  2336  2337  2338  2339  \n",
       "word                                                        \n",
       "인수     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "주민     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "당부     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "시작     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "오픈     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "사건     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "생태     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "수용     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "검사     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "단위     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2597 rows x 2340 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)  \n",
    "community_vectors = encoder.fit_transform(df_merged)\n",
    "pd.DataFrame(community_vectors, index=df_merged.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed78725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building new graph: 100%|██████████| 2597/2597 [00:00<00:00, 3278.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_cluster - 노드 수: 2597, 엣지 수: 291983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)  \n",
    "community_vectors = encoder.fit_transform(df_merged)\n",
    "community_vectors = pd.DataFrame(community_vectors, index=df_merged.index)\n",
    "\n",
    "sim_matrix = cosine_similarity(community_vectors.values)\n",
    "\n",
    "G_cluster = nx.Graph()\n",
    "words = community_vectors.index.tolist()\n",
    "G_cluster.add_nodes_from(words)\n",
    "\n",
    "threshold = 0.3 \n",
    "for i in tqdm(range(len(words)), desc=\"Building new graph\"):\n",
    "    for j in range(i + 1, len(words)):\n",
    "        sim = sim_matrix[i, j]\n",
    "        if sim >= threshold:\n",
    "            G_cluster.add_edge(words[i], words[j], weight=sim)\n",
    "\n",
    "\n",
    "print(f\"G_cluster - 노드 수: {G_cluster.number_of_nodes()}, 엣지 수: {G_cluster.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8be023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엣지 개수: 291983\n",
      "최소 weight: 0.3333333333333334\n",
      "최대 weight: 1.0000000000000002\n",
      "평균 weight: 0.37\n",
      "중앙값 weight: 0.3333333333333334\n",
      "표준편차: 0.11\n"
     ]
    }
   ],
   "source": [
    "# 모든 weight 값 추출\n",
    "weights = [data['weight'] for _, _, data in G_cluster.edges(data=True)]\n",
    "\n",
    "# 통계값 계산\n",
    "print(f\"엣지 개수: {len(weights)}\")\n",
    "print(f\"최소 weight: {np.min(weights)}\")\n",
    "print(f\"최대 weight: {np.max(weights)}\")\n",
    "print(f\"평균 weight: {np.mean(weights):.2f}\")\n",
    "print(f\"중앙값 weight: {np.median(weights)}\")\n",
    "print(f\"표준편차: {np.std(weights):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1a73e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0.333333    260443\n",
       "0.666667     30613\n",
       "1.000000       927\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(weights)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9094702",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74afbe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Resolution: 2.0 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:   6%|▌         | 1/18 [00:02<00:36,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 122\n",
      "\n",
      "================ Resolution: 2.1 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  11%|█         | 2/18 [00:05<00:45,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 122\n",
      "\n",
      "================ Resolution: 2.2 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  17%|█▋        | 3/18 [00:07<00:38,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 126\n",
      "\n",
      "================ Resolution: 2.3 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  22%|██▏       | 4/18 [00:10<00:35,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 130\n",
      "\n",
      "================ Resolution: 2.4 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  28%|██▊       | 5/18 [00:12<00:32,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 131\n",
      "\n",
      "================ Resolution: 2.5 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  33%|███▎      | 6/18 [00:14<00:27,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 130\n",
      "\n",
      "================ Resolution: 2.6 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  39%|███▉      | 7/18 [00:16<00:24,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 131\n",
      "\n",
      "================ Resolution: 2.7 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  44%|████▍     | 8/18 [00:18<00:21,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 131\n",
      "\n",
      "================ Resolution: 2.8 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  50%|█████     | 9/18 [00:21<00:20,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 132\n",
      "\n",
      "================ Resolution: 2.9 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  56%|█████▌    | 10/18 [00:24<00:19,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 133\n",
      "\n",
      "================ Resolution: 3.0 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  61%|██████    | 11/18 [00:27<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 134\n",
      "\n",
      "================ Resolution: 3.1 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  67%|██████▋   | 12/18 [00:29<00:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 136\n",
      "\n",
      "================ Resolution: 3.2 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  72%|███████▏  | 13/18 [00:30<00:11,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 136\n",
      "\n",
      "================ Resolution: 3.3 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  78%|███████▊  | 14/18 [00:33<00:08,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 140\n",
      "\n",
      "================ Resolution: 3.4 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  83%|████████▎ | 15/18 [00:35<00:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 139\n",
      "\n",
      "================ Resolution: 3.5 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  89%|████████▉ | 16/18 [00:37<00:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 142\n",
      "\n",
      "================ Resolution: 3.6 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution:  94%|█████████▍| 17/18 [00:38<00:02,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 145\n",
      "\n",
      "================ Resolution: 3.7 ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Louvain by resolution: 100%|██████████| 18/18 [00:41<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 커뮤니티 수: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_range = np.arange(2.0, 3.8, 0.1)\n",
    "\n",
    "resolutions = [round(x, 1) for x in res_range]\n",
    "\n",
    "resolution_results = {}  # 결과 저장용 딕셔너리\n",
    "\n",
    "for res in tqdm(resolutions, desc=\"Louvain by resolution\"):\n",
    "    print(f\"\\n================ Resolution: {res:.1f} ================\")\n",
    "\n",
    "    partition = community_louvain.best_partition(G_cluster, weight='weight', resolution=res, random_state=RANDOM_STATE)\n",
    "    num_communities = len(set(partition.values()))\n",
    "\n",
    "    community_groups = defaultdict(list)\n",
    "    for node, comm_id in partition.items():\n",
    "        community_groups[comm_id].append(node)\n",
    "\n",
    "    community_groups = dict(sorted(community_groups.items(), key=lambda x: len(x[1]), reverse=True))\n",
    "\n",
    "    # 결과 저장\n",
    "    resolution_results[res] = {\n",
    "        'num_communities': num_communities,\n",
    "        'communities': community_groups\n",
    "    }\n",
    "\n",
    "    print(f\"총 커뮤니티 수: {num_communities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0508dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_communities_by_resolution(res):\n",
    "    print(f\"\\n Resolution: {res}\")\n",
    "    result = resolution_results.get(res)\n",
    "    \n",
    "    if result is None:\n",
    "        print(\"해당 resolution 값의 결과가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"총 커뮤니티 수: {result['num_communities']}\")\n",
    "    \n",
    "    for comm_id, words in result['communities'].items():\n",
    "        print(f\"\\nCommunity {comm_id} ({len(words)}개 단어)\")\n",
    "        print(', '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20c9efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resolution: 3.0\n",
      "총 커뮤니티 수: 134\n",
      "\n",
      "Community 15 (275개 단어)\n",
      "인수, 부동산, 이론, 대기업, 위험성, 성취, 의견, 노력, 가격, 얼마, 저작권, 심사, 안전, 혁신적, 몸값, 돌파구, 초점, 결과, 허용, 영업, 영향력, 체크, 홍보, 경쟁력, 필요성, 수집, 핵심적, 경제적, 기업가치, 소재, 자금, 책임, 투자금, 계약서, 성공, 과금, 중요성, 규모, 크레딧, 게재, 빅데이터, 필수적, 상금, 사업자, 표준, 성공적, 자본, 저장, 전략, 제품, 해양생물, 완성도, 충족, 자연, 결제, 제조, 자원, 점유율, 창업, 산업현장, 사용률, 편향성, 한계, 편의성, 추정, 무기, 부문장, 통합, 유산, 복지, 공장, 진단, 경쟁, 기업가, 획기적, 설문조사, 동기, 안정성, 지급, 선정, 효율성, 식당, 가치, 정상, 체계, 레벨, 효율, 급성장, 수요, 보험, 자본주의, 소득, 마케팅, 금융, 보수, 조직, 신뢰도, 창업자, 제조업, 품질, 성장, 측정, 수입, 신경망, 금액, 자율, 승부, 보상, 성장세, 블록체인, 성취도, 매출, 성공사례, 합리적, 혁신, 유통, 예비, 인기, 경영학, 지속가능, 영업이익, 벤처, 대규모, 수익률, 환경, 선택, 계산, 생태계, 지역균형발전, 성과, 효율화, 전기, 기록, 결정, 자회사, 개선, 주식, 산업혁명, 투자, 발견, 카드, 계정, 매출액, 업그레이드, 사유, 대량, 기업들, 점검, 혁신상, 대상, 쇼핑, 취약, 비용, 증명, 거래, 보호, 자신감, 속도, 자산, 경제성, 사업화, 상점, 요금, 수익화, 수익, 용량, 상품, 완성, 보급, 특허, 재정, 극대화, 최소화, 제작, 성취기준, 개척, 현업, 매장, 효율적, 인상, 예산, 전문가들, 수익성, 농업, 실험, 최대, 스토어, 시험, 비즈니스, 평균, 정확성, 고용, 예방, 계약, 포인트, 정보, 윤리적, 가치관, 맛집, 기업간거래, 핵심, 대형, 예측, 공급, 업계, 수출, 통계, 능동적, 임금, 에너지, 위험, 경제, 중소기업, 대중화, 은행, 판매자, 경쟁사, 검증, 윤리성, 범용적, 조절, 이코노미, 서점, 성취감, 절약, 제한, 재산, 생산, 산업, 긍정적, 체계적, 절반, 퀄리티, 최선, 투자유치, 홈런, 사업, 상거래, 선발, 운용, 마켓, 부작용, 생산성, 판매, 잠재력, 산업계, 발전, 관찰, 컨설팅, 냉장고, 분량, 교환, 회사들, 테스트, 연평균, 정확도, 인프라, 중요, 구매, 능력, 제약, 전문가, 기점, 소비자, 사용량, 손실, 구입, 사업부, 배송, 혜택, 소비, 연산, 장점, 투자자, 결과적\n",
      "\n",
      "Community 14 (262개 단어)\n",
      "성격, 프로젝트, 미디어, 캡처, 가이드북, 맞춤법, 코딩, 웹사이트, 디지털교과서, 프로그램, 가상공간, 개인적, 공학, 챗봇, 인터넷, 정체성, 존재, 장비, 음성합성, 상용, 만화, 프로그래밍, 맞춤, 디지털화, 전문적, 합성, 소셜미디어, 편집자, 휴대폰, 안드로이드, 자동화, 창의성, 가상세계, 지식, 개인, 소프트웨어, 체험학습, 검색엔진, 활용성, 창조, 그림, 프로그래머, 자동, 정보원, 기술적, 자체적, 하드웨어, 머리, 통합검색, 독자적, 채널, 구분, 시각, 사전, 업로드, 도구, 장애인, 체제, 팟캐스트, 사고력, 묘사, 설정, 동영상, 인터랙티브, 필터링, 학습데이터, 시도, 유용, 객관성, 미술, 캐릭터, 전자책, 파일, 스마트, 클릭, 타입, 고객, 인체, 사용법, 출현, 표현력, 기계, 채택, 설치, 글로컬, 취미, 연구개발, 신청, 언어모델, 강화학습, 통제, 메뉴, 조작, 이러닝, 딥러닝, 메모, 상상력, 스마트폰, 종류, 프로필, 멀티미디어, 고객사들, 이용자, 자율주행, 상호작용, 비판, 오픈소스, 발명, 이용, 가상인간, 입력, 활용법, 활성화, 체험공간, 거대언어모델, 트레이닝, 정보통신기술, 모델링, 화면, 테크, 검색, 전문성, 인터뷰, 소통, 창의력, 이미지, 개인화, 음성, 구성, 정보기술, 피아노, 창작물, 시각화, 훈련, 적용, 구조, 창작자, 대화형, 컨텐츠, 모듈, 응용, 브랜드, 로봇, 연습, 통신, 공유, 목소리, 접근, 자기주도학습, 방송, 설계, 음성인식, 링크, 추천, 애플리케이션, 비디오, 노트북, 인사이트, 사이버, 모델들, 키워드, 개인정보, 시제품, 대규모언어모델, 실시간, 예술, 스튜디오, 탐험, 의사소통, 분류, 인식, 맞춤형, 스스로, 게시, 서버, 도서관, 프로토타입, 편리, 드론, 다운로드, 접근성, 사물인터넷, 연결, 디자인, 대화, 기본법, 사용성, 브라우저, 재료, 인터페이스, 온라인, 초개인화, 자율적, 운영툴, 머신러닝, 이용자들, 컴퓨팅, 아티스트, 개발사, 창작, 언어장벽, 집중, 신기술, 형태, 연구팀, 무대, 사이트, 일각, 아트, 패드, 클라우드, 자극, 천재, 도구들, 알고리즘, 고객들, 자문, 모바일, 패턴, 예고, 스크린, 놀이, 코드, 구독자, 트랙, 메모리, 창의적, 컴퓨터, 블로그, 광학문자인식, 디지털전환, 확대, 영상, 편집, 사용, 사용자, 객관적, 장치, 모형, 지적, 기계번역, 쓸모, 가구, 커뮤니케이션, 가상현실, 메이커, 태블릿, 출판사, 면접, 진화, 청사진, 등장인물, 튜닝, 인용, 그래픽, 카메라, 조언, 녹음, 콘셉트, 사진제공, 콘텐츠들, 디자이너\n",
      "\n",
      "Community 1 (199개 단어)\n",
      "주민, 거리, 충돌, 재난, 교통, 축제, 선진국, 논쟁, 건강, 집단, 대한민국, 연애, 전시, 마지막, 박물관, 기념사, 공동체, 관광, 사고, 오늘날, 국립, 일정, 지방자치, 여름, 개월, 방향성, 행복, 열기, 혁명, 기사, 도시, 걱정, 행사장, 가정, 국회, 정의, 주간, 방문, 예약, 공공성, 연속, 전시관, 브로드, 고령층, 사회, 두려움, 사회학, 골든타임, 민관, 추진, 협의회, 차량, 전국, 승리, 인구, 연간, 시대, 최우수상, 긴장, 기회, 인권, 공룡, 투어, 경진, 내년, 콘서트, 행운, 메타버스, 위기, 시중, 고민, 버스, 관람객, 전시회, 새해, 관람객들, 위원회, 참여, 방문객, 과거, 합류, 미래, 공모, 정원, 대중, 관람, 유명, 커뮤니티, 외연, 접목, 박람회, 의심, 운동, 자동차, 아이스크림, 파견, 조치, 법원, 시민들, 협력, 총회, 가을, 민주주의, 월간, 운전, 만남, 수상자, 시위, 기간, 공공, 참가자들, 흐름, 자랑, 정치, 케이크, 그룹, 수년, 공공기관, 지원사업, 음식, 불안, 사흘간, 리더, 경찰, 행정, 조망, 경진대회, 충격, 신문, 가능성, 기념식, 추적, 공포, 날씨, 판결, 지난달, 대표적, 행사, 차별, 역사적, 소송, 개혁, 초대, 질환, 회원, 노동력, 희망, 회의, 사회적, 초청, 외산, 의무, 역설, 의지, 극복, 연말, 상반기, 지역사회, 중심, 질병, 이달, 하루, 마을, 예정, 다음달, 계획, 세기, 선거, 민주, 국가, 일주일, 극대, 공익, 방침, 스트리트, 모임, 지방정부, 주년, 방학, 필수, 역사, 독립, 화재, 상상, 모달, 힌트, 주말, 원인, 소감, 응원, 제안, 노인, 시민, 내달, 분쟁, 장관, 기대감, 논란, 사건\n",
      "\n",
      "Community 8 (197개 단어)\n",
      "에듀, 부모, 공부, 고등학생, 청소년, 연령, 시범학교, 강의, 재학생, 과목, 컨설턴트, 교실, 교양, 교육청, 인문학, 학습지, 초중등, 학술, 학업, 교재, 학부, 교직원, 육아, 탄생, 포럼, 문화, 경험, 가족들, 스쿨, 문헌, 교육자료, 특수교육, 성인, 아카데미, 단원, 코스, 코스웨어, 학원, 문학, 특수학교, 학습효과, 기념, 어린이, 교사, 독서, 학위, 보조교사, 유치원, 지혜, 세미나, 교육과정, 체험, 교과서, 수강생, 배움터, 학령, 실습, 경력, 페이지, 영어학습, 수강, 특강, 클래스, 신입생, 발달, 원도심, 학부모들, 아이디어, 자격, 부모님, 교육자, 리더십, 스토리텔링, 학계, 유아, 중학교, 학습법, 수업사례, 등급, 고등, 학년, 심리, 교육적, 청소년들, 교육기관, 어린이들, 강의실, 학교, 교육현장, 교육혁신, 어린, 인턴, 부진, 캠프, 대학, 인성교육, 공부법, 학습공동체, 학점, 습관, 진학, 체육, 교육학, 토론, 학부모, 학급, 학사, 초등학교, 선생, 교육감, 장학금, 출제, 세대, 숙련, 교과목, 입시, 학기, 교육생, 폭력, 학습량, 차세대, 출생, 현직, 초등, 간담회, 사교육, 대학교, 성적, 인강, 교사들, 초등학생, 주주, 자녀, 학생별, 다차원, 교육비, 에듀테크, 고등학교, 청년, 교환학생, 강좌, 교육업계, 영어교육, 개정안, 교육계, 자격증, 교육열, 선도학교, 가족, 공교육, 베타, 스토리, 아이들, 공감, 설문, 학과, 학습자들, 청년들, 숙제, 인턴십, 벤치, 멘토링, 미래교실, 논술, 아동, 합격, 학생들, 책들, 캠퍼스, 소설, 중학생, 교수들, 산학, 졸업생, 풀타임, 교수, 장학, 나이, 입학설명회, 교과, 교육업체들, 대학생, 커리큘럼, 개정교육, 학습자, 철학, 소수, 학력, 교육업, 학문, 졸업, 문법, 웹페이지, 그림책, 워크숍, 수학, 비유\n",
      "\n",
      "Community 13 (97개 단어)\n",
      "조사, 인류, 응답, 최종, 이동, 디바이드, 태도, 월드, 약점, 외교, 문명, 탄소, 사장, 퍼포먼스, 주권, 중소, 수도, 진입, 근로자, 지수, 독특, 전시장, 초래, 보고서, 불평등, 다문화, 상승, 시사, 하위, 증가, 세계, 외국, 이래, 추가적, 영웅, 설명, 종료, 박사, 사무실, 분리, 제외, 세계관, 지향, 숫자, 초반, 노동, 직종, 마무리, 방한, 팬덤, 평등, 대책, 설명회, 패권, 복합, 얘기, 연봉, 완화, 안정, 의원, 거부, 확정, 동화, 하락, 제거, 연구진, 상징, 촉구, 정기, 추세, 이민자, 계층, 포부, 단체, 물가, 비율, 장기, 파괴, 구사, 가량, 배출, 요인, 대담, 상대적, 세계적, 배달, 지위, 석사, 부족, 상위, 취득, 커리어, 사태, 기후, 수치, 비결, 나라\n",
      "\n",
      "Community 50 (77개 단어)\n",
      "당부, 이행, 부처, 정작, 버튼, 강화, 제도적, 직원, 직속, 유지, 특별, 지역, 균형발전, 존중, 참석, 개방성, 불법, 정책, 공단, 지방, 경계, 고령, 진료, 회복, 심의, 중앙, 정립, 최첨단, 안보, 블루칼라, 약속, 도지사, 다양성, 균형, 원격, 실행력, 분권, 후속, 지속적, 주류, 은퇴, 특구, 거버넌스, 원칙, 주의, 규제, 취임, 역대, 의료, 특례, 출범, 자치, 내국인, 유치, 마스터플랜, 인재들, 재원, 전형, 권한, 진흥, 특별법, 중요시, 종합계획, 종합, 장려, 배려, 국민, 인원, 가사, 단지, 민간, 참관, 대기, 서비스형, 관리사, 생존, 장악\n",
      "\n",
      "Community 16 (77개 단어)\n",
      "확인, 운영사, 소식, 헬스케어, 해설, 챌린지, 획득, 우위, 여행, 주기, 전자, 제재, 주목, 의학, 차례, 수석, 선수, 수수료, 플레이, 호텔, 스포츠, 재단, 부정적, 대응, 헬스, 산업군, 목록, 부사장, 선진, 남녀, 조회수, 소리, 정확, 리서치, 가속화, 컨트롤, 전후, 멀티, 멀티모달, 차단, 관광객, 디렉터, 협회, 할루시네이션, 경기, 접속, 저비용, 주체, 그랜드, 총괄, 해킹, 조정, 기법, 감소, 신속, 요약, 답변, 시니어, 예외, 인텔리전스, 신뢰, 잠재, 삭감, 규칙, 수준, 물류, 에이전트, 이력서, 고령화, 수렴, 다국어, 완벽, 지침, 국제적, 선도자, 선점, 필기\n",
      "\n",
      "Community 12 (75개 단어)\n",
      "원서, 차별화, 지도, 관리, 세션, 커넥트, 건설, 편향, 경영자, 투명성, 오프라인, 브리핑, 연관성, 원천, 운영, 미팅, 임팩트, 얼라이언스, 내비게이션, 멤버십, 관계자, 움직, 밀착, 동참, 긍정, 클럽, 윤리, 재현, 개소, 센터, 프로덕트, 종사자, 시설, 라인업, 본부, 작업, 물건, 이직, 직장인, 화상, 집약, 측위, 출처, 광고주, 선언, 도덕, 메인, 적자, 실과, 직장인들, 책임성, 집행, 콘퍼런스, 트래픽, 업무, 방과, 시나리오, 트윈, 범위, 전산, 빌딩, 책임감, 실내, 근본, 분기, 동료, 측면, 원천기술, 업무협약, 매니저, 조성, 탐색, 의도, 법인, 생태\n",
      "\n",
      "Community 81 (72개 단어)\n",
      "상담실, 버추얼, 지속, 전파, 가상, 만족도, 엔진, 대사, 일환, 상호, 일상, 스터디, 플러스, 마련, 아이돌, 즉각적, 이름, 소속, 유학, 외국인, 실생활, 원활, 증대, 일례, 행동, 인생, 차별성, 계기, 차이, 특화, 추출, 교류, 상담, 발화자, 작용, 차별점, 촉진, 비판적, 시범, 동작, 시간, 고도화, 단축, 유선, 관심사, 상무, 소요, 문자화, 매력, 생활, 상대, 생명, 케이팝, 속도감, 역할, 장기적, 신제품, 본격화, 가공, 팝업, 체류, 일관, 자리매김, 콘텐트, 피드백, 관계자들, 소개팅, 시티, 애니메이션, 통번역, 활동, 고충\n",
      "\n",
      "Community 51 (70개 단어)\n",
      "소양, 노출, 자기, 사례집, 포함, 성향, 지도안, 게시물, 기준, 서비스들, 정착, 각종, 노트, 요소, 다짐, 스타, 인성, 명령, 문제해결, 거짓, 물론, 연계성, 명시, 자료, 개정, 노동자들, 게이미피케이션, 탐지, 앵커, 사례들, 교원, 출연, 과학, 도우미, 구체, 유초등, 본인, 드라이브, 탑재, 실행, 재해, 안내, 타인, 유해, 대두, 리포트, 결국, 삭제, 모니터링, 가짜, 법안, 워터마크, 능가, 해고, 악용, 말씀, 얼굴, 실천, 연계, 노동자, 장착, 일반인, 정시, 자료실, 허위, 유포, 일반인들, 함양, 가짜뉴스, 것들\n",
      "\n",
      "Community 34 (69개 단어)\n",
      "적정, 좌우, 오피스, 진짜, 쇼츠, 출신, 호응, 미적분, 모의고사, 강연, 순서, 내신, 시행착오, 연락, 국제, 정도, 발간, 현안, 리터러시, 위상, 표방, 사항, 이날, 시절, 실용, 언어학, 말뭉치, 보유, 백과사전, 주가, 현지, 프라이버시, 토픽, 무시, 현대, 여지, 백과전, 난이도, 드림, 폭발, 학년도, 동영, 여부, 서술, 예시, 그동안, 당장, 상태, 지분, 전통, 육박, 문맥, 예전, 제어, 염두, 머신, 실전, 업퍼바운드, 중장년층, 백과전서, 코로나, 세상, 대체, 입지, 수행, 출시, 항목, 우리나라, 머릿속\n",
      "\n",
      "Community 7 (67개 단어)\n",
      "오픈, 파트너십, 편의, 복습, 최신, 순위, 특성, 지시문, 범용, 유형, 성능, 구조화, 벤치마크, 구동, 질의응답, 활용도, 감각, 화학, 개방, 크기, 싱크탱크, 사내, 용도, 카테고리, 문서, 사원, 일상적, 한마당, 추론, 전작, 유익, 쿼리, 최적화, 기여, 온디바이스, 주인공, 자기주도, 공격, 법률, 시행, 목적, 마크, 도달, 안전성, 실제, 주기적, 외부, 처리, 데이터베이스, 전력, 비교, 자연어, 종합적, 입증, 부스, 절감, 가속, 동일, 취약점, 신뢰성, 공정, 점수, 촉발, 별도, 차지, 경량화, 경량\n",
      "\n",
      "Community 25 (63개 단어)\n",
      "대회, 참가자, 토크, 러닝, 공감대, 프롬프트, 참가, 신고, 컨퍼런스, 조심, 관리자, 대전환, 예선, 순식간, 확률, 추가, 눈길, 원고, 기조, 문화적, 치수, 조기, 연주, 단속, 카페, 접수, 상장, 창의, 융합, 코칭, 각광, 엔지니어, 범죄, 원리, 지원자, 거주, 안정적, 모양, 피해, 에세이, 본선, 체험존, 음악, 재창작, 일상생활, 고등부, 수원, 축구, 지리적, 개최, 수여, 중등, 역량, 조종, 확산, 조명, 안착, 다큐, 도모, 의식, 업종, 공공데이터, 도내\n",
      "\n",
      "Community 3 (61개 단어)\n",
      "눈앞, 출간, 갈등, 언팩, 엔터, 문자, 종교, 국민들, 선두, 독창적, 전쟁, 진보, 어르신들, 원동력, 장르, 수식, 파트너사, 미션, 정서, 사상, 호평, 풀이, 입사, 중시, 후보, 동네, 작품, 판독, 상식, 영토, 겨냥, 지배, 친절, 사기, 유저, 작가, 유로, 매개, 감정, 작가들, 오답, 엔터테인먼트, 울트라, 성별, 오랫동안, 변수, 가전, 독자들, 직전, 집계, 정답, 무장, 웨어러블, 대답, 공존, 출판, 후기, 중동, 장애, 레시피, 멤버\n",
      "\n",
      "Community 11 (60개 단어)\n",
      "법무, 메일, 관내, 물음, 전면, 친밀, 형식, 퀴즈, 누적, 데이터센터, 제휴, 키오스크, 조금, 동식물, 병행, 견인, 입법, 심화, 최소, 투입, 비속어, 아바타, 우주, 한편, 달성, 조립, 창출, 선제적, 몰입도, 마이, 가입자, 고교, 영역, 캐릭터들, 진로, 비중, 목격, 차시, 단순, 재직, 자사, 니즈, 건수, 신규, 전개, 한정, 빈도, 다양화, 건전, 고도, 마이룸, 공간, 합성어, 동물, 돌파, 욕설, 판사, 유토피아, 키즈, 비서\n",
      "\n",
      "Community 18 (59개 단어)\n",
      "우리말, 한마디, 전제, 왼쪽, 수단, 주문, 열풍, 인간, 번역, 종이, 일들, 언급, 지정, 부합, 페어, 논의, 순간, 대세, 초안, 전통적, 의사, 도약, 통화, 평생, 촬영, 토대, 감안, 입학, 반복, 선도, 말투, 오류, 무한, 설립, 산하, 전달, 포기, 친숙, 명령어, 글자, 주도, 표현, 느낌, 사람들, 의미, 고유, 등장, 실질적, 도출, 작곡, 도서, 현지시간, 해소, 어휘, 마음, 외국인들, 수정, 환자, 제정\n",
      "\n",
      "Community 57 (59개 단어)\n",
      "시청자, 부여, 기억, 마스터, 유출, 취향, 정식, 개시, 버즈, 시리즈, 증강, 효과음, 문장, 실장, 선착순, 드로잉, 배치, 교정, 커버, 친구, 발화, 사옥, 현상, 단어, 가입, 업데이트, 어휘력, 길이, 감상, 이벤트, 영단어, 참여자, 프리토킹, 프리, 첫선, 인물, 입체, 공식, 발음, 아이, 흥미, 론칭, 토킹, 실력, 자유, 스피킹, 플랜, 효과, 실감, 북클럽, 반영, 직업, 회화, 확장현실, 원어민, 시청, 영어회화, 플레이어, 정신\n",
      "\n",
      "Community 19 (58개 단어)\n",
      "공개, 점프스타트, 무료, 파트너, 겨울, 이중, 순차적, 이외, 스트레스, 인스트럭션, 결합, 소셜, 기초, 발판, 위주, 소방, 동력, 전용, 바람, 관리툴, 매개변수, 치매, 파트너들, 전기차, 민원, 최고, 소장, 기본, 진도, 게임사, 개인별, 명칭, 전송, 전문지식, 바이오, 허브, 대비, 러시아, 지사, 도메인, 실현, 소형, 권위, 무분별, 독창성, 협업, 중형, 이중언어, 자체, 게임, 도전, 유사, 서부, 응대, 선별, 초기, 이력, 비상\n",
      "\n",
      "Community 22 (58개 단어)\n",
      "근거, 실물, 유도, 개념, 침해, 발행사, 이해, 기기, 대시보드, 현황, 합의, 저하, 절차, 서책, 반대, 무리, 시연, 억양, 해결책, 단계적, 철저, 패널, 통과, 확충, 법령, 작문, 증강현실, 논리, 제기, 솔루션, 해석, 공무원, 특수, 정비, 일대일, 구독, 규정, 과도, 현실화, 개별, 그래프, 경로, 검정, 제도, 센서, 표시, 미만, 강자, 직접적, 글씨, 도움, 여론, 각자, 구독료, 지자체, 중독, 경고, 단계\n",
      "\n",
      "Community 26 (58개 단어)\n",
      "다각도, 활약, 보안, 양성, 일반적, 두각, 인재, 신설, 편입생, 최다, 강사진, 작성, 개편, 육성, 주행, 시상식, 취업, 일반, 보통, 인력, 이수, 전공, 재편, 심층, 해외, 경영, 국방, 포트폴리오, 교수진, 정규, 개설, 영입, 중순, 총장, 인증, 개교, 모집, 트렌드, 마케터, 국외, 바우처, 교내, 원년, 신입, 진출, 발생, 네트워킹, 원장, 수립, 직무, 재학, 대행, 실무, 매칭, 스트리밍, 프로세스, 전액, 유수\n",
      "\n",
      "Community 28 (52개 단어)\n",
      "지리, 가늠, 내재, 오디오, 근무, 국장, 표창, 하이브리드, 항공, 하이퍼스케일, 한반도, 컨택, 공통, 로드맵, 자리, 협약, 증진, 지평, 자국어, 터보, 한국판, 원본, 영예, 프로, 폐쇄, 전수, 부정확, 통역사, 지표, 보편, 로컬, 추후, 계열, 온프레미스, 위성, 문항, 이공, 방지, 해양, 주관, 매뉴얼, 채점, 전반적, 기획자, 조교, 양상, 구도, 광범위, 상담원, 사내망, 평가, 음원\n",
      "\n",
      "Community 24 (51개 단어)\n",
      "나중, 문제집, 선행, 눈동자, 탐구, 주도적, 총통, 요구, 선생님, 하이테크, 매력적, 요즘, 주력, 재미, 질문, 유료, 향상, 고전, 중단, 라디오, 여건, 토의, 포스터, 강제, 본질, 장면, 아나운서, 드라마, 배경, 양식, 전망, 자신, 친구들, 하이터치, 연수, 관측, 마당, 요청, 호기심, 시선, 우수, 사진, 블록, 발굴, 최종적, 양질, 동아리, 깊이, 신장, 풍경, 교장\n",
      "\n",
      "Community 27 (48개 단어)\n",
      "서류, 양자, 원전, 케어, 형성, 아티피셜, 가능, 팩토리, 중복, 그중, 실증, 독점, 뇌파, 엔터프라이즈, 배터리, 덕분, 지문, 판도, 유리, 발행, 사례, 반도체, 작동, 다큐먼트, 물리, 선도적, 아이템, 만족, 구축, 보장, 확신, 유일, 부품, 치료, 확보, 동의, 스타트업들, 효과적, 채용, 진실, 피카, 정제, 소모, 알파벳, 추격, 적합, 소사이어티, 검사\n",
      "\n",
      "Community 23 (45개 단어)\n",
      "메시지, 움직임, 용어, 절대적, 모빌리티, 거론, 인사, 연기, 임원, 성우, 배우, 더빙, 지시, 수록, 번역기, 감지, 상대방, 텍스트, 이메일, 무궁무진, 조합, 구성원, 청구, 물결, 변환, 대본, 출력, 노래, 행위, 전화, 이어폰, 보안성, 표정, 댄스, 모션, 스크립트, 메신저, 타이어, 구성원들, 휴머노이드, 부정, 야기, 행보, 소스, 채팅\n",
      "\n",
      "Community 36 (43개 단어)\n",
      "디테일, 준수, 상용화, 근간, 내부적, 고객센터, 문의, 스택, 토종, 하이퍼, 고품질, 런칭, 거대, 버티컬, 변경, 무상, 확장성, 인정, 컴퍼니, 통신사, 스킬, 빅테크, 환각, 출격, 커스텀, 초거대, 서치, 신중, 병원, 네트워크, 데이터셋, 주자, 증시, 패키지, 연동, 승인, 방탈출, 완전, 토큰, 내부, 칼로, 풀스택, 파라미터\n",
      "\n",
      "Community 20 (42개 단어)\n",
      "혼자, 가명, 대국민, 장관상, 유망, 성황리, 대면, 저작자, 불편, 댓글, 투명, 버튜버, 주변, 공로, 기분, 요리, 나머지, 페스티벌, 직원들, 크리에이터들, 저작물, 개막, 분위기, 체험관, 공모전, 로고, 홈페이지, 초보자, 권리, 몰입감, 게시판, 원래, 날개, 사랑, 파일럿, 크리에이터, 격려, 웹툰, 감사, 감독, 저작, 모방\n",
      "\n",
      "Community 29 (42개 단어)\n",
      "킬러, 간과, 질의, 필자, 주장, 일자리, 반복적, 연사, 평소, 축소, 암기, 표절, 과학자, 플러그인, 고수, 당국, 심포지엄, 저자, 대안, 사정, 제출, 근본적, 연구자들, 여정, 대입, 배제, 국어, 나름, 직면, 위협, 부담, 편견, 사실, 수능, 전체적, 초록, 문해력, 일상화, 수험생, 의장, 저명, 연구자\n",
      "\n",
      "Community 38 (38개 단어)\n",
      "시작, 등록, 광고, 급증, 수상, 빌더, 이사, 준비, 여성, 우수성, 어젠, 기자간담회, 전당, 첫걸음, 최적, 엣지, 사물, 금상, 타이틀, 자막, 공연, 애드테크, 어시스턴트, 라이브, 문구, 착수, 캠페인, 감성, 해커톤, 분들, 팬데믹, 포털, 소상공인, 안녕, 광고비, 인플루언서, 소외, 한류\n",
      "\n",
      "Community 21 (37개 단어)\n",
      "취재, 바둑, 과장, 상담사, 위원, 강국, 변화, 인문, 방송사, 화제, 매체, 모범, 성찰, 재구성, 언론, 언론사, 직장, 디자, 연구소, 적응, 출발, 기자들, 지원단, 중점, 전환, 콜센터, 외국어, 동향, 자료집, 급변, 부장, 보도, 멘토, 심도, 편성, 내실, 일자\n",
      "\n",
      "Community 42 (36개 단어)\n",
      "전무, 타깃, 노하우, 생성형, 박차, 팀장, 눈높이, 프리미엄, 수주, 전년, 영어권, 공략, 국산, 낚시, 화가, 상조, 어학, 업체들, 첨삭, 체결, 시너지, 홀맨, 튜터, 궁금증, 기획, 화두, 흑자, 연내, 현지화, 실사, 역임, 독해, 선임, 실적, 몰입, 가칭\n",
      "\n",
      "Community 69 (28개 단어)\n",
      "반등, 유니버스, 자국, 신약, 종목, 경영진, 사활, 배분, 복귀, 클래스팅, 리스크, 침투, 발언, 현실, 종속, 불가능, 확장, 이익, 난제, 학회, 동시, 파워, 아내, 과외, 제조사, 국가들, 거짓말, 구별\n",
      "\n",
      "Community 35 (13개 단어)\n",
      "실수, 싸움, 실패, 반응, 장벽, 문제점, 문제들, 복수, 어려움, 혼란, 파급력, 폭발적, 부상\n",
      "\n",
      "Community 39 (2개 단어)\n",
      "네이티브, 식별\n",
      "\n",
      "Community 53 (2개 단어)\n",
      "통역, 지점\n",
      "\n",
      "Community 55 (2개 단어)\n",
      "입장, 자세\n",
      "\n",
      "Community 63 (2개 단어)\n",
      "일종, 고급\n",
      "\n",
      "Community 64 (2개 단어)\n",
      "생각, 예상\n",
      "\n",
      "Community 72 (2개 단어)\n",
      "위치, 장소\n",
      "\n",
      "Community 93 (2개 단어)\n",
      "다수, 대다수\n",
      "\n",
      "Community 31 (1개 단어)\n",
      "사람\n",
      "\n",
      "Community 37 (1개 단어)\n",
      "격차\n",
      "\n",
      "Community 43 (1개 단어)\n",
      "파악\n",
      "\n",
      "Community 44 (1개 단어)\n",
      "업체\n",
      "\n",
      "Community 45 (1개 단어)\n",
      "진행\n",
      "\n",
      "Community 47 (1개 단어)\n",
      "현장\n",
      "\n",
      "Community 49 (1개 단어)\n",
      "방식\n",
      "\n",
      "Community 56 (1개 단어)\n",
      "선호\n",
      "\n",
      "Community 58 (1개 단어)\n",
      "구상\n",
      "\n",
      "Community 59 (1개 단어)\n",
      "제시\n",
      "\n",
      "Community 60 (1개 단어)\n",
      "유의미\n",
      "\n",
      "Community 62 (1개 단어)\n",
      "의문\n",
      "\n",
      "Community 65 (1개 단어)\n",
      "단점\n",
      "\n",
      "Community 66 (1개 단어)\n",
      "유입\n",
      "\n",
      "Community 67 (1개 단어)\n",
      "통찰\n",
      "\n",
      "Community 68 (1개 단어)\n",
      "방법\n",
      "\n",
      "Community 70 (1개 단어)\n",
      "연관\n",
      "\n",
      "Community 71 (1개 단어)\n",
      "방안\n",
      "\n",
      "Community 73 (1개 단어)\n",
      "특정\n",
      "\n",
      "Community 75 (1개 단어)\n",
      "강조\n",
      "\n",
      "Community 76 (1개 단어)\n",
      "독자\n",
      "\n",
      "Community 77 (1개 단어)\n",
      "점유\n",
      "\n",
      "Community 78 (1개 단어)\n",
      "스타일\n",
      "\n",
      "Community 80 (1개 단어)\n",
      "중간\n",
      "\n",
      "Community 82 (1개 단어)\n",
      "영화\n",
      "\n",
      "Community 83 (1개 단어)\n",
      "해결\n",
      "\n",
      "Community 85 (1개 단어)\n",
      "개입\n",
      "\n",
      "Community 87 (1개 단어)\n",
      "제목\n",
      "\n",
      "Community 88 (1개 단어)\n",
      "기관\n",
      "\n",
      "Community 89 (1개 단어)\n",
      "단독\n",
      "\n",
      "Community 90 (1개 단어)\n",
      "부서\n",
      "\n",
      "Community 91 (1개 단어)\n",
      "습득\n",
      "\n",
      "Community 92 (1개 단어)\n",
      "추구\n",
      "\n",
      "Community 94 (1개 단어)\n",
      "주최\n",
      "\n",
      "Community 95 (1개 단어)\n",
      "검토\n",
      "\n",
      "Community 96 (1개 단어)\n",
      "동반\n",
      "\n",
      "Community 98 (1개 단어)\n",
      "차원\n",
      "\n",
      "Community 99 (1개 단어)\n",
      "협의\n",
      "\n",
      "Community 100 (1개 단어)\n",
      "모습\n",
      "\n",
      "Community 101 (1개 단어)\n",
      "시점\n",
      "\n",
      "Community 102 (1개 단어)\n",
      "독보적\n",
      "\n",
      "Community 103 (1개 단어)\n",
      "방향\n",
      "\n",
      "Community 104 (1개 단어)\n",
      "비전\n",
      "\n",
      "Community 105 (1개 단어)\n",
      "발휘\n",
      "\n",
      "Community 106 (1개 단어)\n",
      "무선\n",
      "\n",
      "Community 107 (1개 단어)\n",
      "각국\n",
      "\n",
      "Community 108 (1개 단어)\n",
      "소개\n",
      "\n",
      "Community 109 (1개 단어)\n",
      "신경\n",
      "\n",
      "Community 110 (1개 단어)\n",
      "이야기\n",
      "\n",
      "Community 111 (1개 단어)\n",
      "축적\n",
      "\n",
      "Community 112 (1개 단어)\n",
      "조건\n",
      "\n",
      "Community 113 (1개 단어)\n",
      "의존\n",
      "\n",
      "Community 114 (1개 단어)\n",
      "특징\n",
      "\n",
      "Community 115 (1개 단어)\n",
      "대처\n",
      "\n",
      "Community 116 (1개 단어)\n",
      "조회\n",
      "\n",
      "Community 117 (1개 단어)\n",
      "뒷받침\n",
      "\n",
      "Community 118 (1개 단어)\n",
      "판단\n",
      "\n",
      "Community 119 (1개 단어)\n",
      "정리\n",
      "\n",
      "Community 120 (1개 단어)\n",
      "구애\n",
      "\n",
      "Community 121 (1개 단어)\n",
      "참고\n",
      "\n",
      "Community 122 (1개 단어)\n",
      "체감\n",
      "\n",
      "Community 123 (1개 단어)\n",
      "개개인\n",
      "\n",
      "Community 124 (1개 단어)\n",
      "이슈\n",
      "\n",
      "Community 125 (1개 단어)\n",
      "바탕\n",
      "\n",
      "Community 126 (1개 단어)\n",
      "선포\n",
      "\n",
      "Community 127 (1개 단어)\n",
      "포괄\n",
      "\n",
      "Community 128 (1개 단어)\n",
      "영향\n",
      "\n",
      "Community 129 (1개 단어)\n",
      "취지\n",
      "\n",
      "Community 130 (1개 단어)\n",
      "패러다임\n",
      "\n",
      "Community 131 (1개 단어)\n",
      "유행\n",
      "\n",
      "Community 132 (1개 단어)\n",
      "디바이스\n",
      "\n",
      "Community 133 (1개 단어)\n",
      "사이\n",
      "\n",
      "Community 0 (1개 단어)\n",
      "전반\n",
      "\n",
      "Community 2 (1개 단어)\n",
      "가지\n",
      "\n",
      "Community 4 (1개 단어)\n",
      "전문\n",
      "\n",
      "Community 5 (1개 단어)\n",
      "주제\n",
      "\n",
      "Community 6 (1개 단어)\n",
      "적극\n",
      "\n",
      "Community 9 (1개 단어)\n",
      "유발\n",
      "\n",
      "Community 10 (1개 단어)\n",
      "경향\n",
      "\n",
      "Community 17 (1개 단어)\n",
      "보완\n",
      "\n",
      "Community 30 (1개 단어)\n",
      "보조\n",
      "\n",
      "Community 32 (1개 단어)\n",
      "첨단\n",
      "\n",
      "Community 33 (1개 단어)\n",
      "관심\n",
      "\n",
      "Community 40 (1개 단어)\n",
      "맥락\n",
      "\n",
      "Community 41 (1개 단어)\n",
      "이해도\n",
      "\n",
      "Community 46 (1개 단어)\n",
      "개국\n",
      "\n",
      "Community 48 (1개 단어)\n",
      "상황\n",
      "\n",
      "Community 52 (1개 단어)\n",
      "활성\n",
      "\n",
      "Community 54 (1개 단어)\n",
      "강사\n",
      "\n",
      "Community 61 (1개 단어)\n",
      "공동\n",
      "\n",
      "Community 74 (1개 단어)\n",
      "부탁\n",
      "\n",
      "Community 79 (1개 단어)\n",
      "모색\n",
      "\n",
      "Community 84 (1개 단어)\n",
      "치열\n",
      "\n",
      "Community 86 (1개 단어)\n",
      "수용\n",
      "\n",
      "Community 97 (1개 단어)\n",
      "단위\n"
     ]
    }
   ],
   "source": [
    "print_communities_by_resolution(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311e2c8",
   "metadata": {},
   "source": [
    "# Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90859886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution:2.0 -> Modularity: 0.5839\n",
      "resolution:2.1 -> Modularity: 0.5832\n",
      "resolution:2.2 -> Modularity: 0.5099\n",
      "resolution:2.3 -> Modularity: 0.4864\n",
      "resolution:2.4 -> Modularity: 0.4805\n",
      "resolution:2.5 -> Modularity: 0.4518\n",
      "resolution:2.6 -> Modularity: 0.4457\n",
      "resolution:2.7 -> Modularity: 0.4486\n",
      "resolution:2.8 -> Modularity: 0.4348\n",
      "resolution:2.9 -> Modularity: 0.4365\n",
      "resolution:3.0 -> Modularity: 0.4091\n",
      "resolution:3.1 -> Modularity: 0.3904\n",
      "resolution:3.2 -> Modularity: 0.3741\n",
      "resolution:3.3 -> Modularity: 0.3701\n",
      "resolution:3.4 -> Modularity: 0.3694\n",
      "resolution:3.5 -> Modularity: 0.3690\n",
      "resolution:3.6 -> Modularity: 0.3667\n",
      "resolution:3.7 -> Modularity: 0.3622\n"
     ]
    }
   ],
   "source": [
    "for i in res_range:\n",
    "    partition = community_louvain.best_partition(G_cluster, weight='weight', resolution=round(i,2), random_state=RANDOM_STATE)\n",
    "    modularity = community_louvain.modularity(partition, G_cluster, weight='weight')\n",
    "    print(f\"resolution:{round(i,2)}\", \"->\", f\"Modularity: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a89cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modularity scores saved.\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# modularity_scores = {\n",
    "#     \"modularity\": community_louvain.modularity(community_louvain.best_partition(G_cluster, weight='weight', resolution=3.0, random_state=RANDOM_STATE), \n",
    "#                                                    G_cluster, weight='weight'),\n",
    "# }\n",
    "\n",
    "# with open(\"/Users/kookbab/Desktop/연구 정리 KCI/코드/05. Metrics/modularities/meta_community.json\", \"w\") as f:\n",
    "#     json.dump(modularity_scores, f, indent=4)\n",
    "\n",
    "# print(\"✅ Modularity scores saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d468341",
   "metadata": {},
   "source": [
    "# Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f64b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 불러오기\n",
    "with open(\"/Users/kookbab/Desktop/연구 정리 KCI/코드/04.making_graphs/tokenized_docs.pkl\", \"rb\") as f:\n",
    "    tokenized_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66eba87",
   "metadata": {},
   "source": [
    "# Save Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da71dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_v': 0.5008508993689544, 'u_mass': -11.219104709652585, 'c_uci': -11.792623395070565, 'c_npmi': -0.4081514224331184, 'c_w2v': 0.70552087}\n",
      "{'c_v': 0.4971438496233945, 'u_mass': -11.258154697615266, 'c_uci': -11.839864122948853, 'c_npmi': -0.40974890423923266, 'c_w2v': 0.70555997}\n",
      "{'c_v': 0.48229195131156755, 'u_mass': -11.006429562467204, 'c_uci': -11.624715344826027, 'c_npmi': -0.39914508110253843, 'c_w2v': 0.7099032}\n",
      "{'c_v': 0.48141870200659714, 'u_mass': -11.169947674519403, 'c_uci': -11.553437930691802, 'c_npmi': -0.39577585921709174, 'c_w2v': 0.7214625}\n",
      "{'c_v': 0.4788512014906908, 'u_mass': -11.225429541695672, 'c_uci': -11.5572292612852, 'c_npmi': -0.3960661055694669, 'c_w2v': 0.7230113}\n",
      "{'c_v': 0.46790658958575526, 'u_mass': -10.793227360047036, 'c_uci': -11.500730326153153, 'c_npmi': -0.3944050625663619, 'c_w2v': 0.72297865}\n",
      "{'c_v': 0.4711978791004278, 'u_mass': -10.933839157534443, 'c_uci': -11.569526198813232, 'c_npmi': -0.39705577794568014, 'c_w2v': 0.7231285}\n",
      "{'c_v': 0.46965514750853565, 'u_mass': -10.90478907540089, 'c_uci': -11.492048849553079, 'c_npmi': -0.39342626596560737, 'c_w2v': 0.7265428}\n",
      "{'c_v': 0.46590871511257237, 'u_mass': -10.744192451995866, 'c_uci': -11.439381608570127, 'c_npmi': -0.391423672721394, 'c_w2v': 0.7244861}\n",
      "{'c_v': 0.4683249994002809, 'u_mass': -10.674826993697986, 'c_uci': -11.455076825233313, 'c_npmi': -0.3917713592187133, 'c_w2v': 0.72787875}\n",
      "{'c_v': 0.46792092553162534, 'u_mass': -10.540254422246292, 'c_uci': -11.408181114604464, 'c_npmi': -0.389791661499657, 'c_w2v': 0.72731197}\n",
      "{'c_v': 0.46982103224676475, 'u_mass': -10.744296805179728, 'c_uci': -11.452252969615373, 'c_npmi': -0.3919843829743432, 'c_w2v': 0.722206}\n",
      "{'c_v': 0.4720710531641781, 'u_mass': -10.645532238093908, 'c_uci': -11.426068811477663, 'c_npmi': -0.3916098599756023, 'c_w2v': 0.7174639}\n",
      "{'c_v': 0.46470204709345686, 'u_mass': -10.458712490316374, 'c_uci': -11.390769529715072, 'c_npmi': -0.39027577799884766, 'c_w2v': 0.7187434}\n",
      "{'c_v': 0.4603106855619342, 'u_mass': -10.399320547486813, 'c_uci': -11.357485073626865, 'c_npmi': -0.3889699530011971, 'c_w2v': 0.72001565}\n",
      "{'c_v': 0.4648478104721994, 'u_mass': -10.491489167284286, 'c_uci': -11.363499893649633, 'c_npmi': -0.3888475107940905, 'c_w2v': 0.7201466}\n",
      "{'c_v': 0.46225981510240755, 'u_mass': -10.427570201869141, 'c_uci': -11.361489829401359, 'c_npmi': -0.3886002747430193, 'c_w2v': 0.7214583}\n",
      "{'c_v': 0.46196882333744105, 'u_mass': -10.38983611255483, 'c_uci': -11.313328473618059, 'c_npmi': -0.3863049546626548, 'c_w2v': 0.7217365}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "for i in res_range:\n",
    "\n",
    "    # 원하는 resolution 값 지정\n",
    "    selected_resolution = round(i,2)\n",
    "\n",
    "    # resolution 결과에서 커뮤니티 단어 리스트 추출\n",
    "    communities = resolution_results[selected_resolution]['communities']\n",
    "\n",
    "    # 10개 미만 커뮤니티 제외\n",
    "    filtered_communities = [words for words in communities.values() if len(words) >= 10]\n",
    "\n",
    "    # Dictionary 및 Corpus 생성\n",
    "    dictionary = Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "\n",
    "    # 다양한 coherence metric 계산\n",
    "    coherence_scores = {}\n",
    "    metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
    "    for metric in metrics:\n",
    "        cm = CoherenceModel(\n",
    "            topics=filtered_communities,\n",
    "            texts=tokenized_docs,\n",
    "            corpus=corpus if metric in ['u_mass'] else None,\n",
    "            dictionary=dictionary,\n",
    "            coherence=metric\n",
    "        )\n",
    "        coherence_scores[metric] = cm.get_coherence()\n",
    "\n",
    "    # Word2Vec coherence 추가 계산\n",
    "    try:\n",
    "        from gensim.models import Word2Vec\n",
    "        # 학습된 Word2Vec 모델 불러오기 또는 생성 (예: w2v_model)\n",
    "        w2v_model = Word2Vec(tokenized_docs, vector_size=100, window=5, min_count=2, workers=4, epochs=10, seed=RANDOM_STATE)\n",
    "\n",
    "        cm_w2v = CoherenceModel(\n",
    "            topics=filtered_communities,\n",
    "            texts=tokenized_docs,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_w2v',\n",
    "            keyed_vectors=w2v_model.wv\n",
    "        )\n",
    "        coherence_scores['c_w2v'] = cm_w2v.get_coherence()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Word2Vec coherence 계산 실패:\", e)\n",
    "        coherence_scores['c_w2v'] = None\n",
    "\n",
    "    print(coherence_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f88fcf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence scores saved to /Users/kookbab/Desktop/연구 정리 KCI/코드/05. Metrics/coherence/meta_community.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'c_v': 0.46792092553162534,\n",
       " 'u_mass': -10.540254422246292,\n",
       " 'c_uci': -11.408181114604464,\n",
       " 'c_npmi': -0.389791661499657,\n",
       " 'c_w2v': 0.7258339524269104}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # 원하는 resolution 값 지정\n",
    "# selected_resolution = 3.0\n",
    "\n",
    "# # resolution 결과에서 커뮤니티 단어 리스트 추출\n",
    "# communities = resolution_results[selected_resolution]['communities']\n",
    "\n",
    "# # 10개 미만 커뮤니티 제외\n",
    "# filtered_communities = [words for words in communities.values() if len(words) >= 10]\n",
    "\n",
    "# # Dictionary 및 Corpus 생성\n",
    "# dictionary = Dictionary(tokenized_docs)\n",
    "# corpus = [dictionary.doc2bow(text) for text in tokenized_docs]\n",
    "\n",
    "# # 다양한 coherence metric 계산\n",
    "# coherence_scores = {}\n",
    "# metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
    "# for metric in metrics:\n",
    "#     cm = CoherenceModel(\n",
    "#         topics=filtered_communities,\n",
    "#         texts=tokenized_docs,\n",
    "#         corpus=corpus if metric in ['u_mass'] else None,\n",
    "#         dictionary=dictionary,\n",
    "#         coherence=metric\n",
    "#     )\n",
    "#     coherence_scores[metric] = cm.get_coherence()\n",
    "\n",
    "\n",
    "# try:\n",
    "    \n",
    "#     w2v_model = Word2Vec(tokenized_docs, vector_size=100, window=5, min_count=2, workers=4, epochs=10,  seed=RANDOM_STATE)\n",
    "\n",
    "#     cm_w2v = CoherenceModel(\n",
    "#         topics=filtered_communities,\n",
    "#         texts=tokenized_docs,\n",
    "#         dictionary=dictionary,\n",
    "#         coherence='c_w2v',\n",
    "#         keyed_vectors=w2v_model.wv\n",
    "#     )\n",
    "#     coherence_scores['c_w2v'] = cm_w2v.get_coherence().astype('float64')\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"Word2Vec coherence 계산 실패:\", e)\n",
    "#     coherence_scores['c_w2v'] = None\n",
    "\n",
    "\n",
    "# output_path = f\"/Users/kookbab/Desktop/연구 정리 KCI/코드/05. Metrics/coherence/meta_community.json\"\n",
    "# with open(output_path, \"w\") as f:\n",
    "#     json.dump(coherence_scores, f, indent=4)\n",
    "\n",
    "# print(f\"Coherence scores saved to {output_path}\")\n",
    "\n",
    "# coherence_scores\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
